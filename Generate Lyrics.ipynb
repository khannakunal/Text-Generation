{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [32, 64]\n",
    "batch_sizes = [16, 32]\n",
    "embedding_sizes = [256, 512]\n",
    "lstm_units = [128, 256]\n",
    "\n",
    "combinations = list(zip(sequence_lengths, batch_sizes, embedding_sizes, lstm_units))\n",
    "\n",
    "lstm_layers = 3\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '.\\\\model'\n",
    "\n",
    "def build_model(sequence_length, batch_size, embedding_size, lstm_units_count):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, batch_input_shape = (1, 1)))\n",
    "\n",
    "    for i in range(lstm_layers):\n",
    "        model.add(LSTM(lstm_units_count, return_sequences = (i != 2), stateful = True))\n",
    "        model.add(Dropout(rate = dropout_rate))\n",
    "\n",
    "    model.add(Dense(vocab_size, activation = 'softmax'))\n",
    "    \n",
    "    file_name = 'Sequence length={} batch_size={} embedding_size={} lstm_units_count={}.model.h5'.format(sequence_length, batch_size, embedding_size, lstm_units_count)\n",
    "    model.load_weights(save_dir + '\\\\'  + file_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '.\\\\model'\n",
    "\n",
    "def load_model_with_params(sequence_length, batch_size, embedding_size, lstm_units_count):\n",
    "    file_name = 'Sequence length={} batch_size={} embedding_size={} lstm_units_count={}.model.h5'.format(sequence_length, batch_size, embedding_size, lstm_units_count)\n",
    "    model = load_model(save_dir + '\\\\' + file_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = save_dir + '\\\\char_to_index.json'\n",
    "\n",
    "with open(file_name) as f:\n",
    "    char_to_index = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_char = {index: char for char, index in char_to_index.items()}\n",
    "vocab_size = len(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\n",
      "***************************************************************************************************************\n",
      "mis final you sirt it like I wanto step clased\n",
      "I kissible\n",
      "Makes that I swallow you face\n",
      "You can we comes worre?\n",
      "Let me apritelt for mysrhy\n",
      "And I there from you go\n",
      "I'm stastani let me I vould look away\n",
      "On the sky hopes let me break\n",
      "And then it'n up who want to feel on me\n",
      "What I know, yeah has to let me and to muth something I know, 'em the flamen, to begin see time that I keep less happy the faing in you\n",
      "In the enemy\n",
      "No I have thoughtls you get back like I'm go, to fisa\n",
      "I nad at I quicter, confusing and what you when under this one somehow' come, someone to wish I f\n",
      "To say all fage and there's prothing me the pinged in in our back back elpised bewon exll\n",
      "I've lever promise\n",
      "So I'm about you\n",
      "So? you?\n",
      "I hoeâghing what it, doesn't never way?\n",
      "I can't stre\n",
      "I'd right in a Valentide\n",
      "And I can't ever were ster fall\n",
      "Holding unwer all this\n",
      "The ugomhere\n",
      "Thy is out everyone of acti're not lay the back aining in you eway\n",
      "'Cause I got, memory\n",
      "And is never think up and throw'y to bed\n",
      "I'm throw it got f \n",
      "***************************************************************************************************************\n",
      "\n",
      "***************************************************************************************************************\n",
      "€Sake of the ending\n",
      "There another semors they pain\n",
      "I remember that you're gone\n",
      "Like me myself to begin to the face it\n",
      "I'm just talking to myself\n",
      "Talking to myself\n",
      "Talking to myself\n",
      "Talking to myself\n",
      "Pathles choser to the factor from you\n",
      "The back you wat the end of\n",
      "The finder asading within\n",
      "The sacrifice I diding like the listening\n",
      "I can't feel the last time that with the hard say todight\n",
      "(Let me go\n",
      "And your veace aren't someone else\n",
      "But you turn your back of you\n",
      "And the shadow of the shadow you can't be someone to truly looking at the end of\n",
      "And the vilent tome inside a pistle to be ignored\n",
      "Puilding it up\n",
      "Let me go\n",
      "Little things give you away)\n",
      "All you've ever wanted (Don't tu\n",
      "And lock to fate\n",
      "You'll stop what I' ocean\n",
      "Deverse what it's bringing me tell the way\n",
      "I hate through was something, I want to feel like I'm not alone\n",
      "It's trying not at the end of\n",
      "The final masquerade\n",
      "Standing at the end\n",
      "It doesn't even meat assore\n",
      "And before they lisher the light goes out?\n",
      "If your raing me away\n",
      "Wh\n",
      "***************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for sequence_length, batch_size, embedding_size, lstm_units_count in combinations:\n",
    "    \n",
    "    chars_to_generate = 1000\n",
    "    next_random = np.random.randint(0, vocab_size)\n",
    "    random_sequence = []\n",
    "    random_sequence.append(next_random)\n",
    "    \n",
    "    model = build_model(sequence_length, batch_size, embedding_size, lstm_units_count)\n",
    "    \n",
    "    for i in np.arange(chars_to_generate):\n",
    "        x_input = np.array([next_random]).reshape(1, 1)\n",
    "        probability_vector = model.predict_on_batch(x_input).ravel()\n",
    "        next_random = np.random.choice(np.arange(0, vocab_size), p = probability_vector)\n",
    "        random_sequence.append(next_random)\n",
    "    \n",
    "    generated_text = ''.join([index_to_char[ix] for ix in random_sequence])\n",
    "    print()\n",
    "    print('***************************************************************************************************************')\n",
    "    print(generated_text)\n",
    "    print('***************************************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
